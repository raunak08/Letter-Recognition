{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model based on Discriminant Analysis is - \n",
      "0.650375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "letters = pd.read_csv('letter_data.csv')\n",
    "#letters\n",
    "\n",
    "p=PCA()\n",
    "\n",
    "# covariance=letters.corr(method='pearson',)\n",
    "# print(covariance)\n",
    "\n",
    "training_points= p.fit_transform(training_points)\n",
    "\n",
    "training_points = np.array(letters[:16000].drop(['letter','x-box','y-box ','width','high ','onpix ','xybar','xegvy',], 1))\n",
    "training_labels = np.array(letters[:16000]['letter'])\n",
    "\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(training_points, training_labels)\n",
    "\n",
    "test_points = p.transform(test_points)\n",
    "\n",
    "test_points = np.array(letters[4000:].drop(['letter','x-box','y-box ','width','high ','onpix ','xybar','xegvy'], 1))\n",
    "test_labels = np.array(letters[4000:]['letter'])\n",
    "predicts = clf.predict(test_points)\n",
    "\n",
    "accuracy = clf.score(test_points, test_labels)\n",
    "\n",
    "print(\"The accuracy of model based on Discriminant Analysis is - \")\n",
    "print(float(accuracy))\n",
    "\n",
    "# expected = test_labels\n",
    "# predicted = clf.predict(test_points)\n",
    "\n",
    "# # # # summarize the fit of the model\n",
    "# print(metrics.classification_report(expected, predicted))\n",
    "# print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = test_labels\n",
    "predicted = clf.predict(test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.88      0.86      0.87       629\n",
      "          B       0.44      0.68      0.54       606\n",
      "          C       0.65      0.75      0.69       569\n",
      "          D       0.62      0.75      0.68       639\n",
      "          E       0.49      0.26      0.34       617\n",
      "          F       0.70      0.62      0.66       629\n",
      "          G       0.57      0.46      0.51       620\n",
      "          H       0.32      0.21      0.25       566\n",
      "          I       0.72      0.82      0.77       592\n",
      "          J       0.91      0.72      0.80       576\n",
      "          K       0.57      0.62      0.59       599\n",
      "          L       0.94      0.76      0.84       617\n",
      "          M       0.71      0.83      0.76       626\n",
      "          N       0.73      0.75      0.74       638\n",
      "          O       0.55      0.66      0.60       604\n",
      "          P       0.81      0.70      0.75       643\n",
      "          Q       0.59      0.57      0.58       645\n",
      "          R       0.60      0.67      0.63       621\n",
      "          S       0.37      0.37      0.37       590\n",
      "          T       0.84      0.73      0.78       640\n",
      "          U       0.81      0.76      0.78       652\n",
      "          V       0.75      0.85      0.80       608\n",
      "          W       0.78      0.80      0.79       628\n",
      "          X       0.35      0.51      0.42       621\n",
      "          Y       0.75      0.46      0.57       626\n",
      "          Z       0.71      0.71      0.71       599\n",
      "\n",
      "avg / total       0.66      0.65      0.65     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[540   1   0   0   0   0   0   9   2   6  10   1   2   0  10   0   3   0\n",
      "   23   0   3   1   6   2  10   0]\n",
      " [  0 413   0  13   0   1   6   6  35   0   4   0   0   0  14   3  16  38\n",
      "   34   0   0   0   0  23   0   0]\n",
      " [  0  17 424   1  12   1  20   0   0   0  49   0   4   0  14   0  15   1\n",
      "    1   0  10   0   0   0   0   0]\n",
      " [  1  14   0 481   0   0   3   5  12   7   0   0   5   9  22   2   0  16\n",
      "   32   0   0   0   0  30   0   0]\n",
      " [  0  47 100   1 159   0  58   0   4   0  15   0   0   0   0   0  36  12\n",
      "    9   4   2   0   0 164   1   5]\n",
      " [  0  45   1  21   0 392   3   1  10   0   3   0   0   2   3  57   0  11\n",
      "   12  14   1   4   4  22  23   0]\n",
      " [  3  45  98  12  26   0 284   7   0   0  22   1  10   1  13   0  54  20\n",
      "   15   0   0   0   2   5   0   2]\n",
      " [  2  18   3  43   0   2   3 120   0   0  41   0   6  78  65   6  11  37\n",
      "    5   0  15   2   0  99  10   0]\n",
      " [  0  40   0   9   8   1   1   0 486   4   0   0   0   0   0   7   6   5\n",
      "   23   0   0   0   0   2   0   0]\n",
      " [  0  32   2   6   0   1   0   4  46 413   2   0   0   0   6  22   1   0\n",
      "   29   0   0   0   0  12   0   0]\n",
      " [  0  14  23  15  31   0   8   7   0   0 370   0   2   6   0   0   1  56\n",
      "    2   0  29   0   0  35   0   0]\n",
      " [ 21  27   0   1  19   0  25   1   3   3  21 471   0   0   0   0  13   2\n",
      "    6   0   0   0   0   4   0   0]\n",
      " [ 11   2   0   0   0   0   0   7   0   0   0   0 519  42   4   0   0  11\n",
      "    0   0  13   0  17   0   0   0]\n",
      " [  1   0   0  20   0   0   0  22   0   0   4   0  12 480   9   0   0   2\n",
      "    0   0   1   3  82   1   1   0]\n",
      " [ 10   3   0  51   0   1   4  52   1   2  16   0  24   0 398   0   4  17\n",
      "    0   0   0   0  14   7   0   0]\n",
      " [  0  15   0  31   0  63   6  23  11   0   3   0   2   0   1 447   2  10\n",
      "    2   1   0   4   5   0  17   0]\n",
      " [ 10  63   1  10   9   0  46   5   0   3   4  10   6   0  80   0 369  12\n",
      "    4   0   0   0   1   7   1   4]\n",
      " [  0  56   0  29   0   0   4  20  10   0  38   0   1   7   3   2   5 416\n",
      "    0   0   0   0   0  30   0   0]\n",
      " [ 16  51   0   4   1   6   9   1  24   7   0  16   0   0   0   2  16  13\n",
      "  221   1   0   3   0  90   5 104]\n",
      " [  0   9   0   2   8  53   9   6   0   0  15   0   0   0   5   1   3   0\n",
      "    7 470   3   3   0  31   1  14]\n",
      " [  0   0   4   2   0   0   0  37   0   1  13   0  48  13  39   0   0   1\n",
      "    0   0 493   0   0   1   0   0]\n",
      " [  0   1   0   0   0   3   0  10   0   0  10   0  13   2   5   3   7   8\n",
      "    0   6   6 514  14   1   5   0]\n",
      " [  0   0   0   0   0   0   0  17   0   0   5   0  78  17   0   0   0   2\n",
      "    0   0   0   9 500   0   0   0]\n",
      " [  0  19   0  25  27   0   0   1  31   1   3   0   0   0  32   0  26   5\n",
      "   50   0  22   0   0 318  21  40]\n",
      " [  0   0   0   4   0  34   1  15   0   2   2   0   4   0   6   0  33   0\n",
      "   22  65  10 141   0   2 285   0]\n",
      " [  0   4   0   0  27   1   8   0   1   5   0   0   0   0   1   1   1   0\n",
      "  104   0   0   0   0  22   1 423]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-58226308235a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rfe' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
